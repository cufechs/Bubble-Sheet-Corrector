{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import skimage.io as io\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "#from mlp_train import Net, train, evaluate, detect_digit\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA is not available.  Training on CPU ...\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from skimage.morphology import binary_dilation, binary_erosion\n",
    "from skimage.transform import resize\n",
    "\n",
    "from six.moves import urllib\n",
    "from torchvision import datasets\n",
    "import matplotlib.pyplot as plt\n",
    "import skimage.io as io\n",
    "\n",
    "# check if CUDA is available\n",
    "train_on_gpu = torch.cuda.is_available()\n",
    "\n",
    "if not train_on_gpu:\n",
    "    print('CUDA is not available.  Training on CPU ...')\n",
    "else:\n",
    "    print('CUDA is available!  Training on GPU ...')\n",
    "\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        # convolutional layer\n",
    "        self.conv1 = nn.Conv2d(1, 8, 3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(8, 16, 3, padding=1)\n",
    "        self.conv3 = nn.Conv2d(16, 32, 3, padding=1)\n",
    "        \n",
    "        # max pooling layer\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        \n",
    "        # fc's\n",
    "        self.fc1 = nn.Linear(32 * 4 * 4, 512)\n",
    "        self.fc2 = nn.Linear(512, 32)\n",
    "        self.fc3 = nn.Linear(32, 10)\n",
    "        \n",
    "        self.dropout = nn.Dropout(p=0.5)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # add sequence of convolutional and max pooling layers\n",
    "        \n",
    "        #print(x.shape)\n",
    "        \n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = self.pool(F.relu(self.conv3(x)))\n",
    "        \n",
    "        x = x.view(x.size(0), -1)\n",
    "        \n",
    "        x = self.dropout(x)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = F.relu(self.fc2(x))\n",
    "\n",
    "        x = self.fc3(x)\n",
    "        \n",
    "        return x\n",
    "\n",
    "\n",
    "\n",
    "def load_ds():\n",
    "    \n",
    "    opener = urllib.request.build_opener()\n",
    "    opener.addheaders = [('User-agent', 'Mozilla/5.0')]\n",
    "    urllib.request.install_opener(opener)\n",
    "\n",
    "    ############################################################\n",
    "\n",
    "    num_workers = 0\n",
    "    # how many samples per batch to load\n",
    "    batch_size = 20\n",
    "\n",
    "\n",
    "    # convert data to torch.FloatTensor\n",
    "    transform = transforms.Compose([transforms.RandomRotation(degrees=25),\n",
    "                                    transforms.Resize((32,32)),\n",
    "                                    transforms.ToTensor()\n",
    "                                    ])\n",
    "\n",
    "    # choose the training and test datasets\n",
    "    train_data = datasets.MNIST(root='data', train=True,\n",
    "                                       download=True, transform=transform)\n",
    "    test_data = datasets.MNIST(root='data', train=False,\n",
    "                                      download=True, transform=transform)\n",
    "\n",
    "    # prepare data loaders\n",
    "    train_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size,\n",
    "        num_workers=num_workers)\n",
    "    test_loader = torch.utils.data.DataLoader(test_data, batch_size=batch_size, \n",
    "        num_workers=num_workers)\n",
    "        \n",
    "    return(train_loader,test_loader)\n",
    "    \n",
    "\n",
    "\n",
    "def train(n_epochs=30):\n",
    "\n",
    "    train_loader = load_ds()[0]\n",
    "\n",
    "    model = Net()\n",
    "    if train_on_gpu:\n",
    "        model.cuda()\n",
    "        \n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "\n",
    "    # specify optimizer (stochastic gradient descent) and learning rate = 0.01\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=0.01)\n",
    "\n",
    "    model.train() # prep model for training\n",
    "\n",
    "    for epoch in range(n_epochs):\n",
    "        # monitor training loss\n",
    "        train_loss = 0.0\n",
    "        \n",
    "        ###################\n",
    "        # train the model #\n",
    "        ###################\n",
    "        for data, target in train_loader:\n",
    "            if train_on_gpu:\n",
    "                data, target = data.cuda(), target.cuda()\n",
    "            \n",
    "            # clear the gradients of all optimized variables\n",
    "            optimizer.zero_grad()\n",
    "            # forward pass: compute predicted outputs by passing inputs to the model\n",
    "            output = model(data)\n",
    "            # calculate the loss\n",
    "            loss = criterion(output, target)\n",
    "            # backward pass: compute gradient of the loss with respect to model parameters\n",
    "            loss.backward()\n",
    "            # perform a single optimization step (parameter update)\n",
    "            optimizer.step()\n",
    "            # update running training loss\n",
    "            train_loss += loss.item()*data.size(0)\n",
    "            \n",
    "        # print training statistics \n",
    "        # calculate average loss over an epoch\n",
    "        train_loss = train_loss/len(train_loader.dataset)\n",
    "\n",
    "        print('Epoch: {} \\tTraining Loss: {:.6f}'.format(\n",
    "            epoch+1, \n",
    "            train_loss\n",
    "            ))\n",
    "\n",
    "    #torch.save(model.state_dict(), 'cnn_model_weights.pt')\n",
    "    return model\n",
    "\n",
    "\n",
    "\n",
    "def evaluate(model):\n",
    "\n",
    "    test_loader = load_ds()[1]\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    batch_size = 20\n",
    "    # initialize lists to monitor test loss and accuracy\n",
    "    test_loss = 0.0\n",
    "    class_correct = list(0. for i in range(10))\n",
    "    class_total = list(0. for i in range(10))\n",
    "\n",
    "    model.eval() # prep model for *evaluation*\n",
    "    #if train_on_gpu:\n",
    "    #    model.cuda()\n",
    "\n",
    "    for data, target in test_loader:\n",
    "        if train_on_gpu:\n",
    "            data, target = data.cuda(), target.cuda()\n",
    "        # forward pass\n",
    "        print(data.shape)\n",
    "        output = model(data)\n",
    "        # calculate the loss\n",
    "        loss = criterion(output, target)\n",
    "        # update test loss \n",
    "        test_loss += loss.item()*data.size(0)\n",
    "        # convert output probabilities to predicted class\n",
    "        _, pred = torch.max(output, 1)\n",
    "        # compare predictions to true label\n",
    "        correct = np.squeeze(pred.eq(target.data.view_as(pred)))\n",
    "        # calculate test accuracy for each object class\n",
    "        for i in range(batch_size):\n",
    "            label = target.data[i]\n",
    "            class_correct[label] += correct[i].item()\n",
    "            class_total[label] += 1\n",
    "\n",
    "    # calculate and print avg test loss\n",
    "    test_loss = test_loss/len(test_loader.dataset)\n",
    "    print('Test Loss: {:.6f}\\n'.format(test_loss))\n",
    "\n",
    "    for i in range(10):\n",
    "        if class_total[i] > 0:\n",
    "            print('Test Accuracy of %5s: %2d%% (%2d/%2d)' % (\n",
    "                str(i), 100 * class_correct[i] / class_total[i],\n",
    "                np.sum(class_correct[i]), np.sum(class_total[i])))\n",
    "        else:\n",
    "            print('Test Accuracy of %5s: N/A (no training examples)' % (classes[i]))\n",
    "\n",
    "    print('\\nTest Accuracy (Overall): %2d%% (%2d/%2d)' % (\n",
    "        100. * np.sum(class_correct) / np.sum(class_total),\n",
    "        np.sum(class_correct), np.sum(class_total)))\n",
    "\n",
    "\n",
    "\n",
    "def detect_digit(img, plot=False):\n",
    "       \n",
    "    # image preprocessing\n",
    "    im = resize(img, (114,114))\n",
    "    im = im>0.6\n",
    "    im = np.invert(im)\n",
    "    #im = binary_erosion(im, [[1,1,1,1],[1,1,1,1],[1,1,1,1],[1,1,1,1]])\n",
    "    im = im*255\n",
    "    if plot:\n",
    "        plt.figure()\n",
    "        plt.imshow(im)\n",
    "        \n",
    "    \n",
    "    \n",
    "    # Model loading\n",
    "    model = Net()\n",
    "    model.load_state_dict(torch.load('cnn_model_weights.pt', map_location=torch.device('cpu')))\n",
    "    model.eval()\n",
    "    \n",
    "    im = np.uint8(im)\n",
    "   \n",
    "    transform1 = transforms.Compose([transforms.ToPILImage(),\n",
    "                                    transforms.Grayscale(),\n",
    "                                    transforms.Resize((32,32)),\n",
    "                                    #transforms.ToTensor()\n",
    "                                    ])\n",
    "    \n",
    "    transform2 = transforms.Compose([transforms.ToPILImage(),\n",
    "                                    transforms.ToTensor()\n",
    "                                    ])\n",
    "    \n",
    "    \n",
    "    print(im)\n",
    "    \n",
    "    im = transform1(im)\n",
    "    im = np.array(im)\n",
    "    im = resize(im, (1,1,32,32))\n",
    "    im = transform2(im)\n",
    "    \n",
    "    #im = ToTensor()(img)\n",
    "    \n",
    "    output = model(im)\n",
    "    _, preds = torch.max(output, 1)\n",
    "    return preds.detach().numpy()[0]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([20, 1, 32, 32])\n",
      "torch.Size([20, 1, 32, 32])\n",
      "torch.Size([20, 1, 32, 32])\n",
      "torch.Size([20, 1, 32, 32])\n",
      "torch.Size([20, 1, 32, 32])\n",
      "torch.Size([20, 1, 32, 32])\n",
      "torch.Size([20, 1, 32, 32])\n",
      "torch.Size([20, 1, 32, 32])\n",
      "torch.Size([20, 1, 32, 32])\n",
      "torch.Size([20, 1, 32, 32])\n",
      "torch.Size([20, 1, 32, 32])\n",
      "torch.Size([20, 1, 32, 32])\n",
      "torch.Size([20, 1, 32, 32])\n",
      "torch.Size([20, 1, 32, 32])\n",
      "torch.Size([20, 1, 32, 32])\n",
      "torch.Size([20, 1, 32, 32])\n",
      "torch.Size([20, 1, 32, 32])\n",
      "torch.Size([20, 1, 32, 32])\n",
      "torch.Size([20, 1, 32, 32])\n",
      "torch.Size([20, 1, 32, 32])\n",
      "torch.Size([20, 1, 32, 32])\n",
      "torch.Size([20, 1, 32, 32])\n",
      "torch.Size([20, 1, 32, 32])\n",
      "torch.Size([20, 1, 32, 32])\n",
      "torch.Size([20, 1, 32, 32])\n",
      "torch.Size([20, 1, 32, 32])\n",
      "torch.Size([20, 1, 32, 32])\n",
      "torch.Size([20, 1, 32, 32])\n",
      "torch.Size([20, 1, 32, 32])\n",
      "torch.Size([20, 1, 32, 32])\n",
      "torch.Size([20, 1, 32, 32])\n",
      "torch.Size([20, 1, 32, 32])\n",
      "torch.Size([20, 1, 32, 32])\n",
      "torch.Size([20, 1, 32, 32])\n",
      "torch.Size([20, 1, 32, 32])\n",
      "torch.Size([20, 1, 32, 32])\n",
      "torch.Size([20, 1, 32, 32])\n",
      "torch.Size([20, 1, 32, 32])\n",
      "torch.Size([20, 1, 32, 32])\n",
      "torch.Size([20, 1, 32, 32])\n",
      "torch.Size([20, 1, 32, 32])\n",
      "torch.Size([20, 1, 32, 32])\n",
      "torch.Size([20, 1, 32, 32])\n",
      "torch.Size([20, 1, 32, 32])\n",
      "torch.Size([20, 1, 32, 32])\n",
      "torch.Size([20, 1, 32, 32])\n",
      "torch.Size([20, 1, 32, 32])\n",
      "torch.Size([20, 1, 32, 32])\n",
      "torch.Size([20, 1, 32, 32])\n",
      "torch.Size([20, 1, 32, 32])\n",
      "torch.Size([20, 1, 32, 32])\n",
      "torch.Size([20, 1, 32, 32])\n",
      "torch.Size([20, 1, 32, 32])\n",
      "torch.Size([20, 1, 32, 32])\n",
      "torch.Size([20, 1, 32, 32])\n",
      "torch.Size([20, 1, 32, 32])\n",
      "torch.Size([20, 1, 32, 32])\n",
      "torch.Size([20, 1, 32, 32])\n",
      "torch.Size([20, 1, 32, 32])\n",
      "torch.Size([20, 1, 32, 32])\n",
      "torch.Size([20, 1, 32, 32])\n",
      "torch.Size([20, 1, 32, 32])\n",
      "torch.Size([20, 1, 32, 32])\n",
      "torch.Size([20, 1, 32, 32])\n",
      "torch.Size([20, 1, 32, 32])\n",
      "torch.Size([20, 1, 32, 32])\n",
      "torch.Size([20, 1, 32, 32])\n",
      "torch.Size([20, 1, 32, 32])\n",
      "torch.Size([20, 1, 32, 32])\n",
      "torch.Size([20, 1, 32, 32])\n",
      "torch.Size([20, 1, 32, 32])\n",
      "torch.Size([20, 1, 32, 32])\n",
      "torch.Size([20, 1, 32, 32])\n",
      "torch.Size([20, 1, 32, 32])\n",
      "torch.Size([20, 1, 32, 32])\n",
      "torch.Size([20, 1, 32, 32])\n",
      "torch.Size([20, 1, 32, 32])\n",
      "torch.Size([20, 1, 32, 32])\n",
      "torch.Size([20, 1, 32, 32])\n",
      "torch.Size([20, 1, 32, 32])\n",
      "torch.Size([20, 1, 32, 32])\n",
      "torch.Size([20, 1, 32, 32])\n",
      "torch.Size([20, 1, 32, 32])\n",
      "torch.Size([20, 1, 32, 32])\n",
      "torch.Size([20, 1, 32, 32])\n",
      "torch.Size([20, 1, 32, 32])\n",
      "torch.Size([20, 1, 32, 32])\n",
      "torch.Size([20, 1, 32, 32])\n",
      "torch.Size([20, 1, 32, 32])\n",
      "torch.Size([20, 1, 32, 32])\n",
      "torch.Size([20, 1, 32, 32])\n",
      "torch.Size([20, 1, 32, 32])\n",
      "torch.Size([20, 1, 32, 32])\n",
      "torch.Size([20, 1, 32, 32])\n",
      "torch.Size([20, 1, 32, 32])\n",
      "torch.Size([20, 1, 32, 32])\n",
      "torch.Size([20, 1, 32, 32])\n",
      "torch.Size([20, 1, 32, 32])\n",
      "torch.Size([20, 1, 32, 32])\n",
      "torch.Size([20, 1, 32, 32])\n",
      "torch.Size([20, 1, 32, 32])\n",
      "torch.Size([20, 1, 32, 32])\n",
      "torch.Size([20, 1, 32, 32])\n",
      "torch.Size([20, 1, 32, 32])\n",
      "torch.Size([20, 1, 32, 32])\n",
      "torch.Size([20, 1, 32, 32])\n",
      "torch.Size([20, 1, 32, 32])\n",
      "torch.Size([20, 1, 32, 32])\n",
      "torch.Size([20, 1, 32, 32])\n",
      "torch.Size([20, 1, 32, 32])\n",
      "torch.Size([20, 1, 32, 32])\n",
      "torch.Size([20, 1, 32, 32])\n",
      "torch.Size([20, 1, 32, 32])\n",
      "torch.Size([20, 1, 32, 32])\n",
      "torch.Size([20, 1, 32, 32])\n",
      "torch.Size([20, 1, 32, 32])\n",
      "torch.Size([20, 1, 32, 32])\n",
      "torch.Size([20, 1, 32, 32])\n",
      "torch.Size([20, 1, 32, 32])\n",
      "torch.Size([20, 1, 32, 32])\n",
      "torch.Size([20, 1, 32, 32])\n",
      "torch.Size([20, 1, 32, 32])\n",
      "torch.Size([20, 1, 32, 32])\n",
      "torch.Size([20, 1, 32, 32])\n",
      "torch.Size([20, 1, 32, 32])\n",
      "torch.Size([20, 1, 32, 32])\n",
      "torch.Size([20, 1, 32, 32])\n",
      "torch.Size([20, 1, 32, 32])\n",
      "torch.Size([20, 1, 32, 32])\n",
      "torch.Size([20, 1, 32, 32])\n",
      "torch.Size([20, 1, 32, 32])\n",
      "torch.Size([20, 1, 32, 32])\n",
      "torch.Size([20, 1, 32, 32])\n",
      "torch.Size([20, 1, 32, 32])\n",
      "torch.Size([20, 1, 32, 32])\n",
      "torch.Size([20, 1, 32, 32])\n",
      "torch.Size([20, 1, 32, 32])\n",
      "torch.Size([20, 1, 32, 32])\n",
      "torch.Size([20, 1, 32, 32])\n",
      "torch.Size([20, 1, 32, 32])\n",
      "torch.Size([20, 1, 32, 32])\n",
      "torch.Size([20, 1, 32, 32])\n",
      "torch.Size([20, 1, 32, 32])\n",
      "torch.Size([20, 1, 32, 32])\n",
      "torch.Size([20, 1, 32, 32])\n",
      "torch.Size([20, 1, 32, 32])\n",
      "torch.Size([20, 1, 32, 32])\n",
      "torch.Size([20, 1, 32, 32])\n",
      "torch.Size([20, 1, 32, 32])\n",
      "torch.Size([20, 1, 32, 32])\n",
      "torch.Size([20, 1, 32, 32])\n",
      "torch.Size([20, 1, 32, 32])\n",
      "torch.Size([20, 1, 32, 32])\n",
      "torch.Size([20, 1, 32, 32])\n",
      "torch.Size([20, 1, 32, 32])\n",
      "torch.Size([20, 1, 32, 32])\n",
      "torch.Size([20, 1, 32, 32])\n",
      "torch.Size([20, 1, 32, 32])\n",
      "torch.Size([20, 1, 32, 32])\n",
      "torch.Size([20, 1, 32, 32])\n",
      "torch.Size([20, 1, 32, 32])\n",
      "torch.Size([20, 1, 32, 32])\n",
      "torch.Size([20, 1, 32, 32])\n",
      "torch.Size([20, 1, 32, 32])\n",
      "torch.Size([20, 1, 32, 32])\n",
      "torch.Size([20, 1, 32, 32])\n",
      "torch.Size([20, 1, 32, 32])\n",
      "torch.Size([20, 1, 32, 32])\n",
      "torch.Size([20, 1, 32, 32])\n",
      "torch.Size([20, 1, 32, 32])\n",
      "torch.Size([20, 1, 32, 32])\n",
      "torch.Size([20, 1, 32, 32])\n",
      "torch.Size([20, 1, 32, 32])\n",
      "torch.Size([20, 1, 32, 32])\n",
      "torch.Size([20, 1, 32, 32])\n",
      "torch.Size([20, 1, 32, 32])\n",
      "torch.Size([20, 1, 32, 32])\n",
      "torch.Size([20, 1, 32, 32])\n",
      "torch.Size([20, 1, 32, 32])\n",
      "torch.Size([20, 1, 32, 32])\n",
      "torch.Size([20, 1, 32, 32])\n",
      "torch.Size([20, 1, 32, 32])\n",
      "torch.Size([20, 1, 32, 32])\n",
      "torch.Size([20, 1, 32, 32])\n",
      "torch.Size([20, 1, 32, 32])\n",
      "torch.Size([20, 1, 32, 32])\n",
      "torch.Size([20, 1, 32, 32])\n",
      "torch.Size([20, 1, 32, 32])\n",
      "torch.Size([20, 1, 32, 32])\n",
      "torch.Size([20, 1, 32, 32])\n",
      "torch.Size([20, 1, 32, 32])\n",
      "torch.Size([20, 1, 32, 32])\n",
      "torch.Size([20, 1, 32, 32])\n",
      "torch.Size([20, 1, 32, 32])\n",
      "torch.Size([20, 1, 32, 32])\n",
      "torch.Size([20, 1, 32, 32])\n",
      "torch.Size([20, 1, 32, 32])\n",
      "torch.Size([20, 1, 32, 32])\n",
      "torch.Size([20, 1, 32, 32])\n",
      "torch.Size([20, 1, 32, 32])\n",
      "torch.Size([20, 1, 32, 32])\n",
      "torch.Size([20, 1, 32, 32])\n",
      "torch.Size([20, 1, 32, 32])\n",
      "torch.Size([20, 1, 32, 32])\n",
      "torch.Size([20, 1, 32, 32])\n",
      "torch.Size([20, 1, 32, 32])\n",
      "torch.Size([20, 1, 32, 32])\n",
      "torch.Size([20, 1, 32, 32])\n",
      "torch.Size([20, 1, 32, 32])\n",
      "torch.Size([20, 1, 32, 32])\n",
      "torch.Size([20, 1, 32, 32])\n",
      "torch.Size([20, 1, 32, 32])\n",
      "torch.Size([20, 1, 32, 32])\n",
      "torch.Size([20, 1, 32, 32])\n",
      "torch.Size([20, 1, 32, 32])\n",
      "torch.Size([20, 1, 32, 32])\n",
      "torch.Size([20, 1, 32, 32])\n",
      "torch.Size([20, 1, 32, 32])\n",
      "torch.Size([20, 1, 32, 32])\n",
      "torch.Size([20, 1, 32, 32])\n",
      "torch.Size([20, 1, 32, 32])\n",
      "torch.Size([20, 1, 32, 32])\n",
      "torch.Size([20, 1, 32, 32])\n",
      "torch.Size([20, 1, 32, 32])\n",
      "torch.Size([20, 1, 32, 32])\n",
      "torch.Size([20, 1, 32, 32])\n",
      "torch.Size([20, 1, 32, 32])\n",
      "torch.Size([20, 1, 32, 32])\n",
      "torch.Size([20, 1, 32, 32])\n",
      "torch.Size([20, 1, 32, 32])\n",
      "torch.Size([20, 1, 32, 32])\n",
      "torch.Size([20, 1, 32, 32])\n",
      "torch.Size([20, 1, 32, 32])\n",
      "torch.Size([20, 1, 32, 32])\n",
      "torch.Size([20, 1, 32, 32])\n",
      "torch.Size([20, 1, 32, 32])\n",
      "torch.Size([20, 1, 32, 32])\n",
      "torch.Size([20, 1, 32, 32])\n",
      "torch.Size([20, 1, 32, 32])\n",
      "torch.Size([20, 1, 32, 32])\n",
      "torch.Size([20, 1, 32, 32])\n",
      "torch.Size([20, 1, 32, 32])\n",
      "torch.Size([20, 1, 32, 32])\n",
      "torch.Size([20, 1, 32, 32])\n",
      "torch.Size([20, 1, 32, 32])\n",
      "torch.Size([20, 1, 32, 32])\n",
      "torch.Size([20, 1, 32, 32])\n",
      "torch.Size([20, 1, 32, 32])\n",
      "torch.Size([20, 1, 32, 32])\n",
      "torch.Size([20, 1, 32, 32])\n",
      "torch.Size([20, 1, 32, 32])\n",
      "torch.Size([20, 1, 32, 32])\n",
      "torch.Size([20, 1, 32, 32])\n",
      "torch.Size([20, 1, 32, 32])\n",
      "torch.Size([20, 1, 32, 32])\n",
      "torch.Size([20, 1, 32, 32])\n",
      "torch.Size([20, 1, 32, 32])\n",
      "torch.Size([20, 1, 32, 32])\n",
      "torch.Size([20, 1, 32, 32])\n",
      "torch.Size([20, 1, 32, 32])\n",
      "torch.Size([20, 1, 32, 32])\n",
      "torch.Size([20, 1, 32, 32])\n",
      "torch.Size([20, 1, 32, 32])\n",
      "torch.Size([20, 1, 32, 32])\n",
      "torch.Size([20, 1, 32, 32])\n",
      "torch.Size([20, 1, 32, 32])\n",
      "torch.Size([20, 1, 32, 32])\n",
      "torch.Size([20, 1, 32, 32])\n",
      "torch.Size([20, 1, 32, 32])\n",
      "torch.Size([20, 1, 32, 32])\n",
      "torch.Size([20, 1, 32, 32])\n",
      "torch.Size([20, 1, 32, 32])\n",
      "torch.Size([20, 1, 32, 32])\n",
      "torch.Size([20, 1, 32, 32])\n",
      "torch.Size([20, 1, 32, 32])\n",
      "torch.Size([20, 1, 32, 32])\n",
      "torch.Size([20, 1, 32, 32])\n",
      "torch.Size([20, 1, 32, 32])\n",
      "torch.Size([20, 1, 32, 32])\n",
      "torch.Size([20, 1, 32, 32])\n",
      "torch.Size([20, 1, 32, 32])\n",
      "torch.Size([20, 1, 32, 32])\n",
      "torch.Size([20, 1, 32, 32])\n",
      "torch.Size([20, 1, 32, 32])\n",
      "torch.Size([20, 1, 32, 32])\n",
      "torch.Size([20, 1, 32, 32])\n",
      "torch.Size([20, 1, 32, 32])\n",
      "torch.Size([20, 1, 32, 32])\n",
      "torch.Size([20, 1, 32, 32])\n",
      "torch.Size([20, 1, 32, 32])\n",
      "torch.Size([20, 1, 32, 32])\n",
      "torch.Size([20, 1, 32, 32])\n",
      "torch.Size([20, 1, 32, 32])\n",
      "torch.Size([20, 1, 32, 32])\n",
      "torch.Size([20, 1, 32, 32])\n",
      "torch.Size([20, 1, 32, 32])\n",
      "torch.Size([20, 1, 32, 32])\n",
      "torch.Size([20, 1, 32, 32])\n",
      "torch.Size([20, 1, 32, 32])\n",
      "torch.Size([20, 1, 32, 32])\n",
      "torch.Size([20, 1, 32, 32])\n",
      "torch.Size([20, 1, 32, 32])\n",
      "torch.Size([20, 1, 32, 32])\n",
      "torch.Size([20, 1, 32, 32])\n",
      "torch.Size([20, 1, 32, 32])\n",
      "torch.Size([20, 1, 32, 32])\n",
      "torch.Size([20, 1, 32, 32])\n",
      "torch.Size([20, 1, 32, 32])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([20, 1, 32, 32])\n",
      "torch.Size([20, 1, 32, 32])\n",
      "torch.Size([20, 1, 32, 32])\n",
      "torch.Size([20, 1, 32, 32])\n",
      "torch.Size([20, 1, 32, 32])\n",
      "torch.Size([20, 1, 32, 32])\n",
      "torch.Size([20, 1, 32, 32])\n",
      "torch.Size([20, 1, 32, 32])\n",
      "torch.Size([20, 1, 32, 32])\n",
      "torch.Size([20, 1, 32, 32])\n",
      "torch.Size([20, 1, 32, 32])\n",
      "torch.Size([20, 1, 32, 32])\n",
      "torch.Size([20, 1, 32, 32])\n",
      "torch.Size([20, 1, 32, 32])\n",
      "torch.Size([20, 1, 32, 32])\n",
      "torch.Size([20, 1, 32, 32])\n",
      "torch.Size([20, 1, 32, 32])\n",
      "torch.Size([20, 1, 32, 32])\n",
      "torch.Size([20, 1, 32, 32])\n",
      "torch.Size([20, 1, 32, 32])\n",
      "torch.Size([20, 1, 32, 32])\n",
      "torch.Size([20, 1, 32, 32])\n",
      "torch.Size([20, 1, 32, 32])\n",
      "torch.Size([20, 1, 32, 32])\n",
      "torch.Size([20, 1, 32, 32])\n",
      "torch.Size([20, 1, 32, 32])\n",
      "torch.Size([20, 1, 32, 32])\n",
      "torch.Size([20, 1, 32, 32])\n",
      "torch.Size([20, 1, 32, 32])\n",
      "torch.Size([20, 1, 32, 32])\n",
      "torch.Size([20, 1, 32, 32])\n",
      "torch.Size([20, 1, 32, 32])\n",
      "torch.Size([20, 1, 32, 32])\n",
      "torch.Size([20, 1, 32, 32])\n",
      "torch.Size([20, 1, 32, 32])\n",
      "torch.Size([20, 1, 32, 32])\n",
      "torch.Size([20, 1, 32, 32])\n",
      "torch.Size([20, 1, 32, 32])\n",
      "torch.Size([20, 1, 32, 32])\n",
      "torch.Size([20, 1, 32, 32])\n",
      "torch.Size([20, 1, 32, 32])\n",
      "torch.Size([20, 1, 32, 32])\n",
      "torch.Size([20, 1, 32, 32])\n",
      "torch.Size([20, 1, 32, 32])\n",
      "torch.Size([20, 1, 32, 32])\n",
      "torch.Size([20, 1, 32, 32])\n",
      "torch.Size([20, 1, 32, 32])\n",
      "torch.Size([20, 1, 32, 32])\n",
      "torch.Size([20, 1, 32, 32])\n",
      "torch.Size([20, 1, 32, 32])\n",
      "torch.Size([20, 1, 32, 32])\n",
      "torch.Size([20, 1, 32, 32])\n",
      "torch.Size([20, 1, 32, 32])\n",
      "torch.Size([20, 1, 32, 32])\n",
      "torch.Size([20, 1, 32, 32])\n",
      "torch.Size([20, 1, 32, 32])\n",
      "torch.Size([20, 1, 32, 32])\n",
      "torch.Size([20, 1, 32, 32])\n",
      "torch.Size([20, 1, 32, 32])\n",
      "torch.Size([20, 1, 32, 32])\n",
      "torch.Size([20, 1, 32, 32])\n",
      "torch.Size([20, 1, 32, 32])\n",
      "torch.Size([20, 1, 32, 32])\n",
      "torch.Size([20, 1, 32, 32])\n",
      "torch.Size([20, 1, 32, 32])\n",
      "torch.Size([20, 1, 32, 32])\n",
      "torch.Size([20, 1, 32, 32])\n",
      "torch.Size([20, 1, 32, 32])\n",
      "torch.Size([20, 1, 32, 32])\n",
      "torch.Size([20, 1, 32, 32])\n",
      "torch.Size([20, 1, 32, 32])\n",
      "torch.Size([20, 1, 32, 32])\n",
      "torch.Size([20, 1, 32, 32])\n",
      "torch.Size([20, 1, 32, 32])\n",
      "torch.Size([20, 1, 32, 32])\n",
      "torch.Size([20, 1, 32, 32])\n",
      "torch.Size([20, 1, 32, 32])\n",
      "torch.Size([20, 1, 32, 32])\n",
      "torch.Size([20, 1, 32, 32])\n",
      "torch.Size([20, 1, 32, 32])\n",
      "torch.Size([20, 1, 32, 32])\n",
      "torch.Size([20, 1, 32, 32])\n",
      "torch.Size([20, 1, 32, 32])\n",
      "torch.Size([20, 1, 32, 32])\n",
      "torch.Size([20, 1, 32, 32])\n",
      "torch.Size([20, 1, 32, 32])\n",
      "torch.Size([20, 1, 32, 32])\n",
      "torch.Size([20, 1, 32, 32])\n",
      "torch.Size([20, 1, 32, 32])\n",
      "torch.Size([20, 1, 32, 32])\n",
      "torch.Size([20, 1, 32, 32])\n",
      "torch.Size([20, 1, 32, 32])\n",
      "torch.Size([20, 1, 32, 32])\n",
      "torch.Size([20, 1, 32, 32])\n",
      "torch.Size([20, 1, 32, 32])\n",
      "torch.Size([20, 1, 32, 32])\n",
      "torch.Size([20, 1, 32, 32])\n",
      "torch.Size([20, 1, 32, 32])\n",
      "torch.Size([20, 1, 32, 32])\n",
      "torch.Size([20, 1, 32, 32])\n",
      "torch.Size([20, 1, 32, 32])\n",
      "torch.Size([20, 1, 32, 32])\n",
      "torch.Size([20, 1, 32, 32])\n",
      "torch.Size([20, 1, 32, 32])\n",
      "torch.Size([20, 1, 32, 32])\n",
      "torch.Size([20, 1, 32, 32])\n",
      "torch.Size([20, 1, 32, 32])\n",
      "torch.Size([20, 1, 32, 32])\n",
      "torch.Size([20, 1, 32, 32])\n",
      "torch.Size([20, 1, 32, 32])\n",
      "torch.Size([20, 1, 32, 32])\n",
      "torch.Size([20, 1, 32, 32])\n",
      "torch.Size([20, 1, 32, 32])\n",
      "torch.Size([20, 1, 32, 32])\n",
      "torch.Size([20, 1, 32, 32])\n",
      "torch.Size([20, 1, 32, 32])\n",
      "torch.Size([20, 1, 32, 32])\n",
      "torch.Size([20, 1, 32, 32])\n",
      "torch.Size([20, 1, 32, 32])\n",
      "torch.Size([20, 1, 32, 32])\n",
      "torch.Size([20, 1, 32, 32])\n",
      "torch.Size([20, 1, 32, 32])\n",
      "torch.Size([20, 1, 32, 32])\n",
      "torch.Size([20, 1, 32, 32])\n",
      "torch.Size([20, 1, 32, 32])\n",
      "torch.Size([20, 1, 32, 32])\n",
      "torch.Size([20, 1, 32, 32])\n",
      "torch.Size([20, 1, 32, 32])\n",
      "torch.Size([20, 1, 32, 32])\n",
      "torch.Size([20, 1, 32, 32])\n",
      "torch.Size([20, 1, 32, 32])\n",
      "torch.Size([20, 1, 32, 32])\n",
      "torch.Size([20, 1, 32, 32])\n",
      "torch.Size([20, 1, 32, 32])\n",
      "torch.Size([20, 1, 32, 32])\n",
      "torch.Size([20, 1, 32, 32])\n",
      "torch.Size([20, 1, 32, 32])\n",
      "torch.Size([20, 1, 32, 32])\n",
      "torch.Size([20, 1, 32, 32])\n",
      "torch.Size([20, 1, 32, 32])\n",
      "torch.Size([20, 1, 32, 32])\n",
      "torch.Size([20, 1, 32, 32])\n",
      "torch.Size([20, 1, 32, 32])\n",
      "torch.Size([20, 1, 32, 32])\n",
      "torch.Size([20, 1, 32, 32])\n",
      "torch.Size([20, 1, 32, 32])\n",
      "torch.Size([20, 1, 32, 32])\n",
      "torch.Size([20, 1, 32, 32])\n",
      "torch.Size([20, 1, 32, 32])\n",
      "torch.Size([20, 1, 32, 32])\n",
      "torch.Size([20, 1, 32, 32])\n",
      "torch.Size([20, 1, 32, 32])\n",
      "torch.Size([20, 1, 32, 32])\n",
      "torch.Size([20, 1, 32, 32])\n",
      "torch.Size([20, 1, 32, 32])\n",
      "torch.Size([20, 1, 32, 32])\n",
      "torch.Size([20, 1, 32, 32])\n",
      "torch.Size([20, 1, 32, 32])\n",
      "torch.Size([20, 1, 32, 32])\n",
      "torch.Size([20, 1, 32, 32])\n",
      "torch.Size([20, 1, 32, 32])\n",
      "torch.Size([20, 1, 32, 32])\n",
      "torch.Size([20, 1, 32, 32])\n",
      "torch.Size([20, 1, 32, 32])\n",
      "torch.Size([20, 1, 32, 32])\n",
      "torch.Size([20, 1, 32, 32])\n",
      "torch.Size([20, 1, 32, 32])\n",
      "torch.Size([20, 1, 32, 32])\n",
      "torch.Size([20, 1, 32, 32])\n",
      "torch.Size([20, 1, 32, 32])\n",
      "torch.Size([20, 1, 32, 32])\n",
      "torch.Size([20, 1, 32, 32])\n",
      "torch.Size([20, 1, 32, 32])\n",
      "torch.Size([20, 1, 32, 32])\n",
      "torch.Size([20, 1, 32, 32])\n",
      "torch.Size([20, 1, 32, 32])\n",
      "torch.Size([20, 1, 32, 32])\n",
      "torch.Size([20, 1, 32, 32])\n",
      "torch.Size([20, 1, 32, 32])\n",
      "torch.Size([20, 1, 32, 32])\n",
      "torch.Size([20, 1, 32, 32])\n",
      "torch.Size([20, 1, 32, 32])\n",
      "torch.Size([20, 1, 32, 32])\n",
      "torch.Size([20, 1, 32, 32])\n",
      "torch.Size([20, 1, 32, 32])\n",
      "torch.Size([20, 1, 32, 32])\n",
      "torch.Size([20, 1, 32, 32])\n",
      "torch.Size([20, 1, 32, 32])\n",
      "torch.Size([20, 1, 32, 32])\n",
      "torch.Size([20, 1, 32, 32])\n",
      "torch.Size([20, 1, 32, 32])\n",
      "torch.Size([20, 1, 32, 32])\n",
      "Test Loss: 0.069897\n",
      "\n",
      "Test Accuracy of     0: 99% (974/980)\n",
      "Test Accuracy of     1: 99% (1130/1135)\n",
      "Test Accuracy of     2: 98% (1017/1032)\n",
      "Test Accuracy of     3: 98% (994/1010)\n",
      "Test Accuracy of     4: 98% (964/982)\n",
      "Test Accuracy of     5: 97% (868/892)\n",
      "Test Accuracy of     6: 97% (935/958)\n",
      "Test Accuracy of     7: 96% (995/1028)\n",
      "Test Accuracy of     8: 96% (936/974)\n",
      "Test Accuracy of     9: 96% (969/1009)\n",
      "\n",
      "Test Accuracy (Overall): 97% (9782/10000)\n"
     ]
    }
   ],
   "source": [
    "### Testing ############################\n",
    "model = Net()\n",
    "model.load_state_dict(torch.load('cnn_model_weights.pt', map_location=torch.device('cpu')))\n",
    "#print(model)\n",
    "evaluate(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_digit(img, plot=False):\n",
    "       \n",
    "    # image preprocessing\n",
    "    im = resize(img, (114,114))\n",
    "    im = im>0.6\n",
    "    im = np.invert(im)\n",
    "    #im = binary_erosion(im, [[1,1,1,1],[1,1,1,1],[1,1,1,1],[1,1,1,1]])\n",
    "    im = im*255\n",
    "    im = resize(im, (32,32))\n",
    "    if plot:\n",
    "        plt.figure()\n",
    "        plt.imshow(im)\n",
    "        \n",
    "    # Model loading\n",
    "    model = Net()\n",
    "    model.load_state_dict(torch.load('cnn_model_weights.pt', map_location=torch.device('cpu')))\n",
    "    model.eval()\n",
    "    \n",
    "    im = np.uint8(im)\n",
    "   \n",
    "    transform1 = transforms.Compose([transforms.ToPILImage(),\n",
    "                                    transforms.ToTensor()\n",
    "                                    ]) \n",
    "    im = transform1(im)\n",
    "\n",
    "    output = model(im.view(1,1,32,32))\n",
    "    _, preds = torch.max(output, 1)\n",
    "    return preds.detach().numpy()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([8])\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "data_transform = transforms.Compose([transforms.ToPILImage(),\n",
    "                                transforms.ToTensor()\n",
    "                                ])\n",
    "\n",
    "im = io.imread('seven.jpeg',as_gray=True)\n",
    "im = resize(im, (114,114))\n",
    "im = im>0.6\n",
    "im = np.invert(im)\n",
    "#im = binary_erosion(im, [[1,1,1,1],[1,1,1,1],[1,1,1,1],[1,1,1,1]])\n",
    "im = im*255\n",
    "\n",
    "im = resize(im, (32,32))\n",
    "plt.figure()\n",
    "plt.imshow(im)\n",
    "\n",
    "im = np.uint8(im)\n",
    "\n",
    "img = im\n",
    "img = data_transform(img)\n",
    "\n",
    "model.eval()\n",
    "\n",
    "idx = torch.topk(model(img.view(1,1,32,32)),1)\n",
    "print(idx[1][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Input type float64 is not supported",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-0983f175e1e9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m## Use Case #######################\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdetect_digit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mio\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'seven.jpeg'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mas_gray\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mplot\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Pridection: '\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-9-9c5036ee2b5d>\u001b[0m in \u001b[0;36mdetect_digit\u001b[1;34m(img, plot)\u001b[0m\n\u001b[0;32m     22\u001b[0m                                     \u001b[0mtransforms\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mToTensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m                                     ]) \n\u001b[1;32m---> 24\u001b[1;33m     \u001b[0mim\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtransform1\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mim\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     25\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m     \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mim\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mview\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m32\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m32\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\PyData\\anaconda3\\envs\\image\\lib\\site-packages\\torchvision\\transforms\\transforms.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, img)\u001b[0m\n\u001b[0;32m     59\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     60\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransforms\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 61\u001b[1;33m             \u001b[0mimg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     62\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\PyData\\anaconda3\\envs\\image\\lib\\site-packages\\torchvision\\transforms\\transforms.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, pic)\u001b[0m\n\u001b[0;32m    170\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    171\u001b[0m         \"\"\"\n\u001b[1;32m--> 172\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_pil_image\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpic\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    173\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    174\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__repr__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\PyData\\anaconda3\\envs\\image\\lib\\site-packages\\torchvision\\transforms\\functional.py\u001b[0m in \u001b[0;36mto_pil_image\u001b[1;34m(pic, mode)\u001b[0m\n\u001b[0;32m    255\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    256\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mmode\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 257\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Input type {} is not supported'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnpimg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    258\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    259\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mImage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfromarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnpimg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: Input type float64 is not supported"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD5CAYAAADhukOtAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/MnkTPAAAACXBIWXMAAAsTAAALEwEAmpwYAAALy0lEQVR4nO3dX4ilhXnH8e+vuq6NWqI1XZZVamKlxYtmlWFriYQ01mC9UaEUvQheCBtKBIX0QlJoLfTClKr0yrJWyVKs1lZFKdJmuwgSKBtHu66r20Yjhrisuw1WtIWuqz69OO/CrMzszM75t8nz/cAw57znPfM+vMx3zp85vG+qCkk//35h3gNImg1jl5owdqkJY5eaMHapCWOXmjhznDsnuQ74K+AM4G+q6p6TrX9WNtbZnDPOJiWdxP/xv3xYR7PcbVnv/9mTnAH8ELgWeBt4Abilql5b6T6/lAvqt3LNurYnaXV7ajfv17vLxj7O0/htwBtV9WZVfQg8Btwwxs+TNEXjxL4F+MmS628PyySdhsZ6zb4WSbYD2wHO5jPT3pykFYzzyH4QuHjJ9YuGZSeoqh1VtVBVCxvYOMbmJI1jnNhfAC5L8vkkZwE3A89MZixJk7bup/FV9VGS24F/YfSvt4er6tWJTSZposZ6zV5VzwLPTmgWSVPkJ+ikJoxdasLYpSaMXWrC2KUmjF1qwtilJoxdasLYpSaMXWrC2KUmjF1qwtilJoxdasLYpSaMXWrC2KUmjF1qwtilJoxdasLYpSaMXWrC2KUmjF1qwtilJsY6I0ySt4APgI+Bj6pqYRJDSZq8SZyy+Xeq6qcT+DmSpsin8VIT48ZewPeSvJhk+yQGkjQd4z6Nv7qqDib5FWBXkv+oqueXrjD8EdgOcDafGXNzktZrrEf2qjo4fD8CPAVsW2adHVW1UFULG9g4zuYkjWHdsSc5J8l5xy8DXwP2T2owSZM1ztP4TcBTSY7/nL+rqn+eyFSSJm7dsVfVm8AXJziLpCnyX29SE8YuNWHsUhPGLjVh7FITxi41YexSE8YuNWHsUhPGLjVh7FITxi41YexSE8YuNWHsUhPGLjVh7FITxi41YexSE8YuNWHsUhPGLjVh7FITxi41YexSE6vGnuThJEeS7F+y7IIku5K8Pnw/f7pjShrXWh7Zvwtc96lldwG7q+oyYPdwXdJpbNXYh/Otv/upxTcAO4fLO4EbJzuWpElb72v2TVV1aLj8DqMzuko6jY39Bl1VFVAr3Z5ke5LFJIvHODru5iSt03pjP5xkM8Dw/chKK1bVjqpaqKqFDWxc5+YkjWu9sT8D3DpcvhV4ejLjSJqWtfzr7VHg34BfT/J2ktuAe4Brk7wO/O5wXdJp7MzVVqiqW1a46ZoJzyJpivwEndSEsUtNGLvUhLFLTRi71ISxS00Yu9SEsUtNGLvUhLFLTRi71ISxS00Yu9SEsUtNGLvUhLFLTRi71ISxS00Yu9SEsUtNGLvUhLFLTRi71ISxS00Yu9TEWk7/9HCSI0n2L1l2d5KDSfYOX9dPd0xJ41rLI/t3geuWWX5/VW0dvp6d7FiSJm3V2KvqeeDdGcwiaYrGec1+e5J9w9P88yc2kaSpWG/sDwCXAluBQ8C9K62YZHuSxSSLxzi6zs1JGte6Yq+qw1X1cVV9AjwIbDvJujuqaqGqFjawcb1zShrTumJPsnnJ1ZuA/SutK+n0cOZqKyR5FPgKcGGSt4E/Bb6SZCtQwFvAN6Y3oqRJWDX2qrplmcUPTWEWSVPkJ+ikJoxdasLYpSaMXWrC2KUmjF1qwtilJoxdasLYpSaMXWrC2KUmjF1qwtilJoxdasLYpSaMXWrC2KUmjF1qwtilJoxdasLYpSaMXWrC2KUmjF1qwtilJlaNPcnFSZ5L8lqSV5PcMSy/IMmuJK8P3z1ts3QaW8sj+0fAt6rqcuAq4JtJLgfuAnZX1WXA7uG6pNPUqrFX1aGqemm4/AFwANgC3ADsHFbbCdw4pRklTcApvWZPcglwBbAH2FRVh4ab3gE2TXY0SZO05tiTnAs8AdxZVe8vva2qitHpm5e73/Yki0kWj3F0rGElrd+aYk+ygVHoj1TVk8Piw0k2D7dvBo4sd9+q2lFVC1W1sIGNk5hZ0jqs5d34MDof+4Gqum/JTc8Atw6XbwWenvx4kiblzDWs8yXg68ArSfYOy74N3AM8nuQ24MfAH0xlQkkTsWrsVfV9ICvcfM1kx5E0LX6CTmrC2KUmjF1qwtilJoxdasLYpSaMXWrC2KUmjF1qwtilJoxdasLYpSaMXWrC2KUmjF1qwtilJoxdasLYpSaMXWrC2KUmjF1qwtilJoxdasLYpSaMXWpiLed6uzjJc0leS/JqkjuG5XcnOZhk7/B1/fTHlbReaznX20fAt6rqpSTnAS8m2TXcdn9V/eX0xpM0KWs519sh4NBw+YMkB4At0x5M0mSd0mv2JJcAVwB7hkW3J9mX5OEk5096OEmTs+bYk5wLPAHcWVXvAw8AlwJbGT3y37vC/bYnWUyyeIyj408saV3WFHuSDYxCf6SqngSoqsNV9XFVfQI8CGxb7r5VtaOqFqpqYQMbJzW3pFO0lnfjAzwEHKiq+5Ys37xktZuA/ZMfT9KkrOXd+C8BXwdeSbJ3WPZt4JYkW4EC3gK+MYX5JE3IWt6N/z6QZW56dvLjSJoWP0EnNWHsUhPGLjVh7FITxi41YexSE8YuNWHsUhPGLjVh7FITxi41YexSE8YuNWHsUhPGLjVh7FITxi41YexSE8YuNWHsUhPGLjVh7FITxi41YexSE8YuNbGWc72dneQHSV5O8mqSPxuWfz7JniRvJPn7JGdNf1xJ67WWR/ajwFer6ouMTs98XZKrgO8A91fVrwH/Ddw2tSkljW3V2Gvkf4arG4avAr4K/OOwfCdw4zQGlDQZaz0/+xnDGVyPALuAHwHvVdVHwypvA1umMqGkiVhT7FX1cVVtBS4CtgG/sdYNJNmeZDHJ4jGOrm9KSWM7pXfjq+o94Dngt4HPJjl+yueLgIMr3GdHVS1U1cIGNo4zq6QxrOXd+M8l+exw+ReBa4EDjKL//WG1W4GnpzSjpAk4c/VV2AzsTHIGoz8Oj1fVPyV5DXgsyZ8D/w48NMU5JY1p1dirah9wxTLL32T0+l3SzwA/QSc1YexSE8YuNWHsUhPGLjWRqprdxpL/An48XL0Q+OnMNr4y5ziRc5zoZ22OX62qzy13w0xjP2HDyWJVLcxl487hHA3n8Gm81ISxS03MM/Ydc9z2Us5xIuc40c/NHHN7zS5ptnwaLzUxl9iTXJfkP4eDVd41jxmGOd5K8kqSvUkWZ7jdh5McSbJ/ybILkuxK8vrw/fw5zXF3koPDPtmb5PoZzHFxkueSvDYc1PSOYflM98lJ5pjpPpnaQV6raqZfwBmMDmv1BeAs4GXg8lnPMczyFnDhHLb7ZeBKYP+SZX8B3DVcvgv4zpzmuBv4oxnvj83AlcPl84AfApfPep+cZI6Z7hMgwLnD5Q3AHuAq4HHg5mH5XwN/eCo/dx6P7NuAN6rqzar6EHgMuGEOc8xNVT0PvPupxTcwOnAnzOgAnivMMXNVdaiqXhouf8Do4ChbmPE+OckcM1UjEz/I6zxi3wL8ZMn1eR6ssoDvJXkxyfY5zXDcpqo6NFx+B9g0x1luT7JveJo/9ZcTSyW5hNHxE/Ywx33yqTlgxvtkGgd57f4G3dVVdSXwe8A3k3x53gPB6C87oz9E8/AAcCmjcwQcAu6d1YaTnAs8AdxZVe8vvW2W+2SZOWa+T2qMg7yuZB6xHwQuXnJ9xYNVTltVHRy+HwGeYr5H3jmcZDPA8P3IPIaoqsPDL9onwIPMaJ8k2cAosEeq6slh8cz3yXJzzGufDNt+j1M8yOtK5hH7C8BlwzuLZwE3A8/Meogk5yQ57/hl4GvA/pPfa6qeYXTgTpjjATyPxzW4iRnskyRhdAzDA1V135KbZrpPVppj1vtkagd5ndU7jJ96t/F6Ru90/gj44znN8AVG/wl4GXh1lnMAjzJ6OniM0Wuv24BfBnYDrwP/Clwwpzn+FngF2Mcots0zmONqRk/R9wF7h6/rZ71PTjLHTPcJ8JuMDuK6j9Eflj9Z8jv7A+AN4B+Ajafyc/0EndRE9zfopDaMXWrC2KUmjF1qwtilJoxdasLYpSaMXWri/wFTpvMzwoyRqAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "## Use Case #######################\n",
    "p = detect_digit(io.imread('seven.jpeg',as_gray=True), plot=True)\n",
    "print('Pridection: ', p)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
